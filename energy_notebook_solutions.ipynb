{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EthiCS : Energy Impact of Machine Learning computation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In the field of computer and data science, every application and object that we develop is consuming energy. From the little model or software to the biggest machine and deep learning application, what you develop is consuming electrical energy and thus has a carbon footprint. However, we're not often explicitly aware of that and we often don't really have a sense of the impact our work has on the environment.\n",
    "\n",
    "In the current global context, where energy and environmental issues are becoming one of the main challenge, it is essential for the new computer and data scientist that are the future of the industry to be aware of this problem and to be able to measure and tackle those issues.\n",
    "\n",
    "Through this notebook, we will try to give you some tools and methods to measure the carbon footprint and energy consumption of your work and to give you some tips to reduce it. We will go through different realistic use cases and you will learn how to easily estimate those aspect of your work with simple python libraries and tools."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the tools\n",
    "\n",
    "#### What is a Jupyter Notebook ?\n",
    "\n",
    "This is a Jupyter Notebook, a web application that allows you to create documents that contain text aswell as live code that you can execute. It is widely used in the data science community and is a great tool to share and present your work. \n",
    "Jupyter notebook are organized in cell, an object where you can write, among other things, code or text. The text cell are written in markdown, an html like language that allows you to easily format your text. To execute code the notebook use what we call a kernel and this kernel will define the language that you will use in your notebook. In this notebook, we will use a python kernel thus the code that we'll write will be in python.\n",
    "\n",
    "#### Why python ?\n",
    "\n",
    "Python is a great language for data science and machine learning. It is easy to learn and to use and has a lot of libraries that will help you to do your work. It is also a great language to use in a notebook because it is easy to read and to understand. One main advantage of python is that is a pretty high-level language so if you already know how to code in java, c or c++ for exemple you will find it really easy to learn. You can really develop anything in python, it is a pretty powerful language and really modular. You can easily install packages to add new functionalities to your code in function of what you need to do.\n",
    "\n",
    "#### Packages ?\n",
    "\n",
    "As we said earlier, python is a really modular language. This modularity is made possible by the use of packages. A package is a set of modules that you can install and use in your code. For exemple, if you want to do some data science you can install the package pandas that will allow you to manipulate data easily. You can install those packages with the pip command in your terminal or in a notebook cell with the prefix **!**. For exemple, if you want to install the pandas package you can do it with the following command : \n",
    "\n",
    "```pip install pandas``` in your terminal or ```!pip install pandas``` in a notebook cell.\n",
    "\n",
    "#### Pip ?\n",
    "\n",
    "Pip is the package installer for python. It is a command line tool that allows you to install packages. When you call pip in your terminal, it will look for the package that you want to install in the python package index (PyPI) and will install it on your computer. You can also use pip to uninstall packages or to upgrade them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup :\n",
    "\n",
    "Now than you know a little bit more about the tools that we will use, we can start to setup our environment. First, we will install the packages that we will use in this notebook. We will use the following packages :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install sklearn\n",
    "!pip install codecarbon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic of Jupyter Notebook\n",
    "\n",
    "In juppyter notebook you can add a cell by pressing the **+** button in the toolbar, by pressing the **a** key to add it above or by pressing the **b** key to add it below. You can delete a cell by pressing the **d** key twice.\n",
    "To edit a code celle you can just click on it and to edit a text cell you need to double click on it. To execute a cell you can click on the **Run** button or press **shift+enter** to execute it and focus the next cell or the **ctrl+enter** to execute it and stay on the same cell. In the tool bar you can run all the cell at once, stop the execution or restart the kernel if you want to clear the variables that you have in memory."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the notebook\n",
    "\n",
    "Now that we saw everything you need in order to start the notebook, we can actually start to code. During this notebook we will use the example of diverse machine learning model provide by the sklearn library for you to learn how to estimate the energy consumption and co2 footprint of python code.\n",
    "\n",
    "#### Import the packages :\n",
    "\n",
    "We can start by importing a package. To do so, we use the **import** keyword followed by the name of the package. We will start by importing pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a package is imported you can use it in your code. To call the method of a package you just have to write the name of the package, or the aliases you defined with the ```as``` keyword, followed by a dot and the name of the method. For exemple, if you want to use the DataFrame method of the pandas package you can do it like this : ```pd.Dataframe(args)``` where pd is the aliases of the pandas package."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data\n",
    "\n",
    "Now that pandas is imported we can use it to import data into python. The dataset we will use during this exercise is the [winequality dataset](https://archive.ics.uci.edu/ml/datasets/wine+quality) provide by the UCI machine learning repository. This dataset contains 12 features and 1599 samples. The goal of this dataset is to predict the quality of a wine based on those features. We will use this dataset to train different machine learning model and to estimate their energy consumption and carbon footprint.\n",
    "\n",
    "the first exercise for you will be to import the dataset into a pandas dataframe. To do so, you can use the pandas function read_csv. This function will allow you to read a csv file and to store it into a dataframe. You can find the documentation of this function [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html). You can find the dataset in the data folder of this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('winequality-red.csv', sep=';')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the dataset is imported in python, there exist some methods that allows you to display some informations about it.\n",
    "\n",
    "- The ```head()``` method allows you to display the first n rows of your dataframe. By default, n is equal to 5 but you can change it by passing the number of rows you want to display as an argument. You can find the documentation of this method [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html).\n",
    "- The ```sample()``` method to display a random sample of your dataframe. You can find the documentation of this method [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html).\n",
    "- The ```tail()``` method that allows you to display the last n rows of your dataframe. You can find the documentation of this method [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.tail.html).\n",
    "- The ```describe()``` method to display some statistics about your dataframe. You can find the documentation of this method [here](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html).\n",
    "- The ```info()``` method to display some informations about your dataframe. You can find the documentation of this method [here](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html).\n",
    "\n",
    "Use those methods to display some informations about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select a column of your dataframe you can use the ```[]``` operator. You can find the documentation of this operator [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.__getitem__.html). You can also use the ```loc[]``` operator to select a row or a range of rows. You can find the documentation of this operator [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html). You can also use the ```iloc[]``` operator to select a row or a range of rows by their index. You can find the documentation of this operator [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html).\n",
    "\n",
    "Use the ```[]```, ```loc[]``` and ```iloc[]``` operators to select the following columns and row of your dataset :\n",
    "\n",
    "- The column ```density```\n",
    "- The 10th row\n",
    "- The 10th to 15th row of the ```density``` column\n",
    "- The 1000th to 1005th rows in 2nd to 5th columns\n",
    "- The rows where the ```pH``` column is equal to 3.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['density']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[10:15,'density']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1000:1005,2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['pH'] == 3.51]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train machine learning algorithm we need to split our dataset into the features and the target. The features are the columns that we will use to train our model, that describe our data, and the target is the column that we want to predict. In our case, the target is the quality column and the features are all the other columns. To split our dataset you can use the method we saw previously and the drop method of the dataframe. This method allows you to drop a column or a row of your dataframe. You can find the documentation of this method [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html).\n",
    "\n",
    "Create a features dataframe and a target dataframe from your dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop('quality', axis=1)\n",
    "target = df['quality']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a model with sklearn\n",
    "\n",
    "Now that we have our features and our target, we can start to train a machine learning model. We will use the sklearn library to train our model. This library contains a lot of machine learning algorithm that you can use. You can find the documentation of this library [here](https://scikit-learn.org/stable/). You will start by learning how to train a [KNN (K-Nearest Neighbors)](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) model, which is the simplest ML model. You can find the documentation of this model [here](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN model is a classification model, which means that it will predict a class for each sample. It works by finding the k nearest neighbors of a sample and by predicting the class of the sample based on the class of its neighbors.\n",
    "\n",
    "To train a model with sklearn you need to follow 3 steps :\n",
    "\n",
    "- Create an instance of the model you want to train\n",
    "- Fit the model with your data\n",
    "- Predict the target of your data\n",
    "\n",
    "You can find more informations about how to train a model with sklearn [here](https://scikit-learn.org/stable/tutorial/basic/tutorial.html).\n",
    "\n",
    "Start by importing the KNearestNeighbour model from the sklearn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, create an instance of the KNN model with the default parameters and train it with your features and target. Finally, predict the target of your features and display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "model = knn.fit(features, target)\n",
    "model.predict(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can check the accuracy of your model. To do so, you can use the accuracy_score method of the sklearn package. You can find the documentation of this method [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html).\n",
    "\n",
    "Check the accuracy of your model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(features, target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate the energy consumption and carbon footprint of your model\n",
    "\n",
    "Finally, you know enough to do basic machine learning in python (of course we presented really briefly the subject, there is a lot more to learn). Now, you will learn how to estimate the energy consumption and carbon footprint of your model. To do so, you will use the package [codecarbon](https://codecarbon.io/). This package allows you to estimate those metrics by estimating the power usage of your CPU and GPU, and by multipling it by the carbon intensity of the country you are in. You can find the documentation on the methodology [here](https://mlco2.github.io/codecarbon/methodology.html).\n",
    "\n",
    "To estimate the power usage of you're CPU, codecarbon uses different methodology if you're on windows, mac or linux :\n",
    "\n",
    "- If you're using Windows/Mac with an intel CPU, you will need to install manually the [Intel Power Gadget](https://www.intel.com/content/www/us/en/developer/articles/tool/power-gadget.html) to estimate the power usage of your CPU.\n",
    "\n",
    "- If you're using Linux with an intel CPU, codecarbon will use the RAPL files to estimate the power usage of your CPU. It is not available for all CPU and you cand find more information about it [here](https://web.eece.maine.edu/~vweaver/projects/rapl/).\n",
    "\n",
    "- If you're not in any of those cases, codecarbon will activate its fallback mode by performing the following steps: Firstly, it will identify the CPU hardware being utilized and match it with a comprehensive data source containing over 2000 Intel and AMD CPUs, along with their respective thermal design powers (TDPs). In case the CPU is not present in the data source, a global constant will be used."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codecarbon provide two object to estimate the energy consumption and carbon footprint of your model : the ```EmissionsTracker``` and the ```OfflineEmissionsTracker``` objects. The ```EmissionsTracker``` object will use internet to detect the country you're in and to get the carbon intensity of this country. The ```OfflineEmissionsTracker``` object will need you to provide explicitly the ```country_iso_code```. Beeing in a country with a low carbon intensity will reduce the carbon footprint of your model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To estimate the energy consumption and carbon footprint of your model, you will need to follow the following steps :\n",
    "\n",
    "- Import the codecarbon package\n",
    "- Create an instance of EmissionsTracker or OfflineEmissionsTracker\n",
    "- start the tracker\n",
    "- Do huge computation/Train your model\n",
    "- stop the tracker\n",
    "\n",
    "Use the codecarbon package to create an offline (with the contry code of United-State) and a online tracker to estimate the energy consumption and carbon footprint of training a predicting a knn model on your dataset (hint you can use the information [here](https://mlco2.github.io/codecarbon/usage.html#) to see code example on how to use the codecarbon package) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codecarbon import EmissionsTracker\n",
    "from codecarbon import OfflineEmissionsTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Online tracker\n",
    "tracker = EmissionsTracker()\n",
    "tracker.start()\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "model = knn.fit(features, target)\n",
    "model.predict(features)\n",
    "\n",
    "tracker.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Offline tracker\n",
    "\n",
    "OfflineTracker = OfflineEmissionsTracker(country_iso_code=\"USA\")\n",
    "OfflineTracker.start()\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "model = knn.fit(features, target)\n",
    "model.predict(features)\n",
    "\n",
    "OfflineTracker.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CodeCarbon store the results of your experiment in a csv file called ```emissions.csv```. You can find this file in the same folder than this notebook. It also print a lot of information directly in the notebook. It will first, when you create the tracker try to identify your hardware and it will print a quick sumary of what he found. Then, when you start the tracker, it will print regularly the energy consumption of your architecture. Finally, when you stop the tracker, it will print the carbon footprint of your experiment.\n",
    "\n",
    "You may notice that here the carbon footprint is really low. It is because the dataset is really small and the model is really simple. In real life, on huge model, like the use in deap learning, that trains on huge dataset during many hours/days, the carbon footprint is a lot higher. Still it is important to be aware of it and to be able to measure this consumption yourself."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final exercise : "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know everything you need, try to increase the number of neighbor of your model and see how it impact the accuracy and the carbon footprint of your model (of course the number of neighbor can't be higher than the number of sample in your dataset), using an Offline tracker in china. Do a for loop to test different number of neighbor and plot the accuracy and the carbon footprint of your model in fucntion of the number of neighbour (you may find it easier to plot it on 2 different graph because the scale of the two metrics will be really different). You can use the matplotlib package to plot your results. You can find the documentation of this package [here](https://matplotlib.org/), you can find information on how to create subplot easily [here](https://matplotlib.org/stable/gallery/subplots_axes_and_figures/subplots_demo.html) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neigh = [2,5,10,50,100,200,500]\n",
    "scores = []\n",
    "footprints = []\n",
    "\n",
    "chinaTracker = OfflineEmissionsTracker(country_iso_code=\"CHN\")\n",
    "chinaTracker.start()\n",
    "\n",
    "for n in n_neigh:\n",
    "    knn = KNeighborsClassifier(n_neighbors=n)\n",
    "    model = knn.fit(features, target)\n",
    "    scores.append(model.score(features, target))\n",
    "    footprints.append(chinaTracker.stop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(15,5))\n",
    "ax1.plot(n_neigh, scores)\n",
    "ax2.plot(n_neigh, footprints)\n",
    "\n",
    "ax1.set_xlabel('number of neighbors')\n",
    "ax1.set_ylabel('accuracy')\n",
    "ax1.set_title('KNN accuracy')\n",
    "\n",
    "ax2.set_xlabel('number of neighbors')\n",
    "ax2.set_ylabel('CO2 footprint (gCO2e)')\n",
    "ax2.set_title('KNN CO2 footprint')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that when the number of neighbour increase the carbon footprint increase too. It is because the model is more complex and need more computation to be trained. Here the accuracy of the mode decrease with the number of neighbour. It is because we train our model on the data we want to predict and this makes no sense in KNN. In real life, you will train your model on a training set and test it on a test set (but here we have few data and the point was more to see the co2 footprint). You can find more information on how to do that [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
